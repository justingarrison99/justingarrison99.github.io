---
layout: post
title: "HW17: Team Progress I"
---

At this point we have, for the most part, nailed down how we want our testing framework to work. There weren't many problems we, as a team, encountered. We all agreed on design principals and no one felt as if they were doing little or too much for the project. The only "issues" we had were the expected hiccups of using a new idea/resource like Python's unittest library, Selenium, and HTMLTestRunner. It took a fair amount of 'doc' diving but this was expected because no one was familiar with the tools we were using. The core of the framework is operable now, we can create test cases, run them, and display the results of those tests. Things we need to do to build upon what we have is.. creating a more verbose output display, so that test cases' ID, requirements, components, expected outputs are included instead of just whether or not the test passed or failed. While not necessarily a problem for the scope of this project, we are sending a list of test case objects to the driver instead of funneling them one by one, this is problematic because when/if we scale the testing framework to work with a large (think thousands, there's alot of web elements to test) it's not resource efficient and may just cause a stackoverflow because of the amount of memory used. This is something to be mindful of though I'm not sure if for the scope of this project we will change the design to a pipeline-esque functionality. In all, we're on track and the fruit of our labor is beginning to show.  
